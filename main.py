from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import yt_dlp
import asyncio
import os
import time
import random
from datetime import datetime
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import json
import re
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Harmony YouTube Downloader API", version="1.0.0")

# CORS middleware to allow frontend requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# YouTube Data API configuration
YOUTUBE_API_KEY = "AIzaSyCCJa0xel2ISGG3MG8VCmV6pMEZF9joDFM"
youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

# Cookie file path (if available)
COOKIE_FILE = "cookies.txt"

class SearchRequest(BaseModel):
    query: str
    max_results: Optional[int] = 10

class VideoInfo(BaseModel):
    id: str
    title: str
    channel: str
    duration: str
    thumbnail: str
    view_count: Optional[int] = None
    upload_date: Optional[str] = None

class DownloadRequest(BaseModel):
    video_id: str
    format: Optional[str] = "bestaudio/best"

class CookieImportRequest(BaseModel):
    cookies_json: str

# Custom headers to mimic browser behavior
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# Create cookies.txt file with the provided cookies
def create_cookies_file():
    """Create the cookies.txt file with the provided cookies"""
    cookies_content = """# Netscape HTTP Cookie File
# This file is generated by yt-dlp.  Do not edit.

.youtube.com	TRUE	/	FALSE	0	PREF	hl=en&tz=UTC
.youtube.com	TRUE	/	TRUE	0	SOCS	CAI
.youtube.com	TRUE	/	TRUE	1756158525	GPS	1
.youtube.com	TRUE	/	TRUE	0	YSC	pb3p_-WYhQc
.youtube.com	TRUE	/	TRUE	1771708726	VISITOR_INFO1_LIVE	toSf0vkumrc
.youtube.com	TRUE	/	TRUE	1771708726	VISITOR_PRIVACY_METADATA	CgJVRxIEGgAgUg%3D%3D
.youtube.com	TRUE	/	TRUE	1771708726	__Secure-ROLLOUT_TOKEN	CLqjwqb487LYrwEQiuivzvGmjwMYrPD6zvGmjwM%3D
.youtube.com	TRUE	/	TRUE	1819228726	__Secure-YT_TVFAS	t=487821&s=2
.youtube.com	TRUE	/	TRUE	1771708726	DEVICE_INFO	ChxOelUwTWpZek5UY3dOVGMyTlRRek56SXlNQT09ELams8UGGLams8UG
.youtube.com	TRUE	/tv	TRUE	1788988726	__Secure-YT_DERP	CMPHmP-HAQ%3D%3D"""
    
    with open(COOKIE_FILE, 'w') as f:
        f.write(cookies_content)
    logger.info(f"Created {COOKIE_FILE} with provided cookies")

# Create cookies file on startup
if not os.path.exists(COOKIE_FILE):
    create_cookies_file()
else:
    logger.info(f"Using existing {COOKIE_FILE}")

async def retry_yt_dlp_operation(operation, max_retries=3, initial_delay=2):
    """Retry yt-dlp operation with exponential backoff"""
    for attempt in range(max_retries):
        try:
            return await operation()
        except yt_dlp.utils.DownloadError as e:
            error_msg = str(e)
            if ("Sign in to confirm you're not a bot" in error_msg or 
                "Unable to extract uploader id" in error_msg or
                "Private video" in error_msg) and attempt < max_retries - 1:
                # Exponential backoff with jitter
                delay = initial_delay * (2 ** attempt) + random.uniform(0, 1)
                logger.warning(f"Download error, retrying in {delay:.2f} seconds (attempt {attempt + 1}/{max_retries})")
                await asyncio.sleep(delay)
                continue
            raise
        except Exception as e:
            if attempt < max_retries - 1:
                delay = initial_delay * (2 ** attempt) + random.uniform(0, 1)
                logger.warning(f"Error occurred, retrying in {delay:.2f} seconds (attempt {attempt + 1}/{max_retries}): {str(e)}")
                await asyncio.sleep(delay)
                continue
            raise
    raise Exception("Max retries exceeded")

@app.post("/api/search", response_model=List[VideoInfo])
async def search_videos(request: SearchRequest):
    """Search YouTube videos using YouTube Data API"""
    try:
        # Use YouTube Data API for search
        search_response = youtube.search().list(
            q=request.query,
            part="snippet",
            maxResults=request.max_results,
            type="video"
        ).execute()
        
        # Extract video IDs for getting additional details
        video_ids = [item['id']['videoId'] for item in search_response['items']]
        
        # Get video details (including duration)
        videos_response = youtube.videos().list(
            part="snippet,contentDetails,statistics",
            id=",".join(video_ids)
        ).execute()
        
        results = []
        for item in videos_response['items']:
            # Format duration from ISO 8601 to readable format
            duration = parse_duration(item['contentDetails']['duration'])
            
            # Format upload date
            upload_date = format_date(item['snippet']['publishedAt'])
            
            # Get view count
            view_count = int(item['statistics'].get('viewCount', 0))
            
            # Get thumbnail (highest resolution available)
            thumbnails = item['snippet']['thumbnails']
            thumbnail = thumbnails.get('high', thumbnails.get('medium', thumbnails.get('default', {}))).get('url', '')
            
            results.append(VideoInfo(
                id=item['id'],
                title=item['snippet']['title'],
                channel=item['snippet']['channelTitle'],
                duration=duration,
                thumbnail=thumbnail,
                view_count=view_count,
                upload_date=upload_date
            ))
        
        return results
        
    except HttpError as e:
        logger.error(f"YouTube API error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"YouTube API error: {str(e)}")
    except Exception as e:
        logger.error(f"Search failed: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")


@app.post("/api/download/{video_id}")
async def download_audio(video_id: str, format: str = "bestaudio/best"):
    """Download audio from YouTube video with retry logic"""
    try:
        # Create downloads directory if it doesn't exist
        os.makedirs("downloads", exist_ok=True)
        
        # Generate unique filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"downloads/{video_id}_{timestamp}.%(ext)s"
        
        # Build yt-dlp options
        ydl_opts = {
            'format': format,
            'outtmpl': filename,
            'quiet': False,
            'http_headers': DEFAULT_HEADERS,
            'socket_timeout': 30,
            'progress_hooks': [progress_hook],
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'extractor_args': {
                'youtube': {
                    'skip': ['dash', 'hls'],
                    'player_client': ['android', 'web'],
                }
            },
        }
        
        # Add cookies if available
        if os.path.exists(COOKIE_FILE):
            ydl_opts['cookiefile'] = COOKIE_FILE
            logger.info(f"Using cookies from {COOKIE_FILE}")
        else:
            logger.warning("No cookies file found. Downloading without cookies may fail for some videos.")
        
        # Additional options to avoid bot detection
        ydl_opts.update({
            'no_check_certificate': True,
            'prefer_insecure': False,
            'verbose': True,
        })
        
        async def download_operation():
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                url = f"https://www.youtube.com/watch?v={video_id}"
                
                # First try to get info without downloading
                info = await asyncio.to_thread(ydl.extract_info, url, download=False)
                
                # Then download
                await asyncio.to_thread(ydl.download, [url])
                
                # Get the actual filename (convert extensions to mp3)
                actual_filename = ydl.prepare_filename(info).replace('.webm', '.mp3').replace('.m4a', '.mp3')
                
                return {
                    "status": "success",
                    "filename": actual_filename,
                    "title": info.get('title', ''),
                    "duration": format_duration(info.get('duration'))
                }
        
        # Use retry logic for the download operation
        return await retry_yt_dlp_operation(download_operation)
            
    except Exception as e:
        logger.error(f"Download failed: {str(e)}")
        import traceback
        traceback.print_exc()
        # Check if it's a cookie-related error
        if "Sign in to confirm you're not a bot" in str(e):
            raise HTTPException(
                status_code=403, 
                detail="YouTube requires authentication. Please import fresh cookies using the cookie import feature."
            )
        raise HTTPException(status_code=500, detail=f"Download failed: {str(e)}")


@app.post("/api/cookies")
async def import_cookies(request: CookieImportRequest):
    """Import cookies from browser extension"""
    try:
        # Parse the cookies JSON
        cookies_data = json.loads(request.cookies_json)
        
        # Convert to Netscape format for yt-dlp
        netscape_cookies = []
        netscape_cookies.append("# Netscape HTTP Cookie File")
        netscape_cookies.append("# This file was generated by Harmony YouTube Downloader")
        netscape_cookies.append("# https://curl.se/docs/http-cookies.html")
        netscape_cookies.append("")
        
        for cookie in cookies_data:
            if 'domain' in cookie and 'name' in cookie and 'value' in cookie:
                domain = cookie['domain']
                if domain.startswith('.'):
                    domain = domain[1:]
                
                # Netscape format: domain, flag, path, secure, expiration, name, value
                flag = "TRUE" if domain.startswith('.') else "FALSE"
                path = cookie.get('path', '/')
                secure = "TRUE" if cookie.get('secure', False) else "FALSE"
                expiration = str(cookie.get('expirationDate', int(time.time()) + 3600))
                name = cookie['name']
                value = cookie['value']
                
                netscape_cookies.append(f"{domain}\t{flag}\t{path}\t{secure}\t{expiration}\t{name}\t{value}")
        
        # Write to cookie file
        with open(COOKIE_FILE, 'w') as f:
            f.write("\n".join(netscape_cookies))
        
        logger.info(f"Cookies imported to {COOKIE_FILE}")
        return {"status": "success", "message": f"Cookies imported to {COOKIE_FILE}"}
    
    except Exception as e:
        logger.error(f"Cookie import failed: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Cookie import failed: {str(e)}")


@app.get("/api/cookies/status")
async def check_cookies():
    """Check if cookies file exists"""
    exists = os.path.exists(COOKIE_FILE)
    size = os.path.getsize(COOKIE_FILE) if exists else 0
    return {"exists": exists, "size": size, "path": os.path.abspath(COOKIE_FILE)}


@app.get("/api/downloads")
async def list_downloads():
    """List all downloaded files"""
    try:
        if not os.path.exists("downloads"):
            return {"downloads": []}
        
        downloads = []
        for filename in os.listdir("downloads"):
            if filename.endswith('.mp3'):
                filepath = os.path.join("downloads", filename)
                downloads.append({
                    "filename": filename,
                    "size": os.path.getsize(filepath),
                    "modified": datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat()
                })
        
        return {"downloads": downloads}
    except Exception as e:
        logger.error(f"Error listing downloads: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error listing downloads: {str(e)}")


def progress_hook(d):
    """Progress hook for download updates"""
    if d['status'] == 'downloading':
        logger.info(f"Downloading: {d.get('_percent_str', '0%')}")
    elif d['status'] == 'finished':
        logger.info("Download completed, converting...")


def format_duration(seconds: Optional[int]) -> str:
    """Convert seconds to MM:SS format, safe for None"""
    if not seconds or not isinstance(seconds, int):
        return "0:00"
    minutes, sec = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{sec:02d}"
    else:
        return f"{minutes}:{sec:02d}"


def parse_duration(duration_str: str) -> str:
    """Parse ISO 8601 duration format to MM:SS"""
    import isodate
    try:
        duration = isodate.parse_duration(duration_str)
        total_seconds = int(duration.total_seconds())
        return format_duration(total_seconds)
    except:
        return "0:00"


def format_date(date_str: str) -> str:
    """Format ISO date to YYYY-MM-DD"""
    try:
        from datetime import datetime
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        return dt.strftime("%Y-%m-%d")
    except:
        return date_str[:10] if len(date_str) >= 10 else ""


@app.get("/")
async def root():
    return {"message": "Harmony YouTube Downloader API", "status": "running"}


@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
